---
title: "Survey"
output: html_document
date: "2025-03-04"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(tidyr)
library(readxl)
library(openxlsx)
library(stringr)
library(ggplot2)
library(ggpubr)
library(sf)
library(tigris)
library(corrplot)
library(purrr)
```

```{r weather data set up, include=FALSE}
# read in weather data

W2020 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Weather data/monthly/TSecon_monthly_weather.xlsx', sheet = '2020')

W2021 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Weather data/monthly/TSecon_monthly_weather.xlsx', sheet = '2021')

# bind all weather data to one frame
W <- rbind(W2020, W2021)

# remove 2020 and 2021 individual dataframes
rm(W2020, W2021)


# tidy weather data

# get month and year, convert to month names
W <- W %>%
  separate(Date, c('Year', 'Month'), '-0')

W$Month <- str_replace_all(W$Month, c("6" = "June", "7" = "July", "8" = "Aug", "9" = "Sept"))

# pivot wider so that each month and weather var is a separate column
W <- W %>%
  pivot_wider(names_from = c('Month', 'Year'), values_from = c(ppt, tmin, tmean, tmax))
```

```{r survey data set up, include=FALSE}
# read in survey response data

S1 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response data/Tar Spot Survey COMPILED.xlsx', sheet = 'Single county') %>%
  unite(County, State, col = "Location", sep = ", ", remove = FALSE) %>%
  drop_na(County)

S2 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response data/Tar Spot Survey COMPILED.xlsx', sheet = 'Multi-county') %>%
  unite(County, State, col = "Location", sep = ", ", remove = FALSE) %>%
  drop_na(County)

S <- rbind(S1,S2)

rm(S1, S2)
```

```{r survey data check, eval=FALSE}

# Does including the data that is derived from correcting percentages and NASS county statistics change the distribution of the data?

test <- S %>%
  mutate(LOSS_2020 = ifelse(is.na(Operations_2020Loss_perc) & is.na(NASS_County_Yield_2020), Operations_2020Loss, Operations_2020Loss_perc*NASS_County_Yield_2020)) %>%
  relocate(LOSS_2020, .after = Operations_2020Loss_perc) %>%
  mutate(LOSS_2021 = ifelse(is.na(Operations_2021Loss_perc) & is.na(NASS_County_Yield_2021), Operations_2021Loss, Operations_2021Loss_perc*NASS_County_Yield_2021)) %>%
  relocate(LOSS_2021, .after = Operations_2021Loss_perc)

hist(test$LOSS_2020)
hist(test$Operations_2020Loss)
hist(test$LOSS_2021)
hist(test$Operations_2021Loss)

# No, so continue with this data included. 

```

```{r survey data cleaning}

S <- S %>%
  # create final loss columns for each year
  mutate(LOSS_2020 = ifelse(is.na(Operations_2020Loss_perc) & is.na(NASS_County_Yield_2020), Operations_2020Loss, Operations_2020Loss_perc*NASS_County_Yield_2020)) %>%
  relocate(LOSS_2020, .after = Operations_2020Loss_perc) %>%
  mutate(LOSS_2021 = ifelse(is.na(Operations_2021Loss_perc) & is.na(NASS_County_Yield_2021), Operations_2021Loss, Operations_2021Loss_perc*NASS_County_Yield_2021)) %>%
  relocate(LOSS_2021, .after = Operations_2021Loss_perc) %>%
  # remove other columns used to create the final LOSS_2020 and LOSS_2021 columns
  select(!c(starts_with('NASS'), contains('Operations_20'), starts_with('Complete')))
  
```

# HEATMAPS

```{r heatmap prep, include=FALSE}
# prep for heatmaps

# retrieve county-level shapefiles for all states
mi_counties <- counties(state = "MI", cb = TRUE) %>%
  st_transform(crs = 4326)
in_counties <- counties(state = "IN", cb = TRUE) %>%
  st_transform(crs = 4326)
oh_counties <- counties(state = "OH", cb = TRUE) %>%
  st_transform(crs = 4326)
ia_counties <- counties(state = "IA", cb = TRUE) %>%
  st_transform(crs = 4326)
wi_counties <- counties(state = "WI", cb = TRUE) %>%
  st_transform(crs = 4326)
il_counties <- counties(state = "IL", cb = TRUE) %>%
  st_transform(crs = 4326)
pa_counties <- counties(state = "PA", cb = TRUE) %>%
  st_transform(crs = 4326)
mo_counties <- counties(state = "MO", cb = TRUE) %>%
  st_transform(crs = 4326)
ny_counties <- counties(state = "NY", cb = TRUE) %>%
  st_transform(crs = 4326)
mn_counties <- counties(state = "MN", cb = TRUE) %>%
  st_transform(crs = 4326)

# Combine the data for all states
combined_counties_raw <- rbind(mi_counties, in_counties, oh_counties, ia_counties, wi_counties, il_counties, pa_counties, mo_counties, ny_counties, mn_counties)

rm(mi_counties, in_counties, oh_counties, ia_counties, wi_counties, il_counties, pa_counties, mo_counties, ny_counties, mn_counties)
```

```{r response count heatmap}
# heat map of responses

# summarize survey data to count responses by county
S_count <- S %>% group_by(County, State) %>% summarise(Responses = n())

# combine geo info with survey data
combined_counties <- left_join(combined_counties_raw, S_count, by = c('NAME'='County', 'STUSPS'='State'))

# Plot the map
ggplot(data = combined_counties) +
  geom_sf(aes(fill = Responses), color = "black") +
  theme_minimal() +
  labs(title = "County-Level Count of Survey Responses") +
  scale_fill_viridis_c(option = "plasma") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5))

rm(S_count, combined_counties)
```

```{r 2020 loss heatmap}
# heat map of losses 2020

S_loss_2020 <- S %>% group_by(County, State) %>% summarise(Loss = ifelse(all(LOSS_2020 == 0), 0, mean(LOSS_2020, na.rm = TRUE)))

# Combine geo info with survey data
combined_counties <- left_join(combined_counties_raw, S_loss_2020, by = c('NAME'='County', 'STUSPS'='State'))

# Plot the map
ggplot(data = combined_counties) +
  geom_sf(aes(fill = Loss), color = "black") +
  theme_minimal() +
  scale_fill_viridis_c(option = "plasma", limits=c(0, 60)) +
  labs(title = "County-Level Reported Losses Due to Tar Spot in 2020") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5))

rm(combined_counties)
```

```{r 2021 loss heatmap}
# heat map of losses 2020

S_loss_2021 <- S %>% group_by(County, State) %>% summarise(Loss = ifelse(all(LOSS_2021 == 0), 0, 
                                                                    mean(LOSS_2021, na.rm = TRUE)))

# Combine geo info with survey data
combined_counties <- left_join(combined_counties_raw, S_loss_2021, by = c('NAME'='County', 'STUSPS'='State'))

# Plot the map
ggplot(data = combined_counties) +
  geom_sf(aes(fill = Loss), color = "black") +
  theme_minimal() +
  scale_fill_viridis_c(option = "plasma", limits=c(0,60)) +
  labs(title = "County-Level Reported Losses Due to Tar Spot in 2021") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5))

rm(combined_counties)
```

```{r clean up, include=FALSE}

rm(combined_counties_raw)
rm(combined_counties)

```

# LOSS HISTOGRAMS

```{r loss histogram}

S_loss_2020 <- S_loss_2020 %>%
  mutate(Year = '2020')
S_loss_2021 <- S_loss_2021 %>%
  mutate(Year = '2021')
S_loss <- rbind(S_loss_2020, S_loss_2021)

ggplot(S_loss, aes(x=Loss)) + 
  geom_histogram(binwidth=1) +
  facet_grid(~Year)

```

```{r clean up2}

rm(S_loss_2020, S_loss_2021, S_loss)

```

## SUMMARIZING CATEGORICAL RESPONSES

### Historical fungicide use

```{r historical fungicide use}

HF <- S %>% select(contains('Hist')) %>% select(!ends_with('Reported')) %>% select(!contains('Other'))

# Removing '_Reported' columns - all data has been cleaned. 
# Also removing observations with entries in "other" actually belonged in existing categories, or were nonsense, so removing

column_sums <- colSums(!is.na(HF))
print(column_sums)

```

```{r historical fungicide program matrix}

# change all Yes to 1

CO <- as.data.frame(ifelse(!is.na(HF) & HF == "Yes", 1, 0))

# Remove rows with no coinfections by counting across data columns and filtering
CO <- CO %>%
  rowwise() %>%
  mutate(coinfection_check = sum(c_across(c("HistFungiStrat_V10",
                                            "HistFungiStrat_V10_14",
                                            "HistFungiStrat_VTR1",
                                            "HistFungiStrat_R2",
                                            "HistFungiStrat_PostR2",
                                            "HistFungiStrat_None" ))))

CO_matrix <- CO %>% 
  count(HistFungiStrat_V10,
        HistFungiStrat_V10_14,
        HistFungiStrat_VTR1, 
        HistFungiStrat_R2, 
        HistFungiStrat_PostR2, 
        HistFungiStrat_None)

# DO NOT OVERWRITE
#write.xlsx(CO_matrix, '/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response data/CO_matrixMultiCounty.xlsx', overwrite=FALSE)

rm(CO, CO_matrix, HF)

```

```{r historical fungicide program visualization}
# Load in fixed matrix

coinfection_data <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response Data/CO_matrix FIXED.xlsx')
colnames(coinfection_data)[1] <- 'X1'

# Melt data so that each combination is represented by its own Row
library(reshape2)
ReshapedData <- melt(coinfection_data, value.name = 'Responses')

# Reorder
mylevels <- c('V10', 'V10-V14', 'VT/R1', 'R2', 'PostR2', 'None')

# reorder factors
ReshapedData$X1 <- factor(ReshapedData$X1,levels=mylevels)
ReshapedData$variable <- factor(ReshapedData$variable, levels=mylevels)
 
# Heatmap 
ggplot(ReshapedData, aes(X1, variable, fill= Responses)) + 
  geom_tile(color = 'white')

rm (ReshapedData, coinfection_data)
```

### Increase in fungicide use

```{r fungicide use - farmers only}

S_fungi_20 <- S %>%
  select(Role_Farmer, Location, contains('Change_2020')) %>%
  select(!contains('Rep')) %>%
  na.omit()

S_fungi_20_n <- nrow(S_fungi_20)

S_fungi_20 <- S_fungi_20 %>%
  group_by(FungiChange_2020) %>%
  summarise(Responses_2020 = n()) %>%
  mutate(perc = Responses_2020/S_fungi_20_n) %>%
  ungroup()

S_fungi_21 <- S %>%
  select(Role_Farmer, Location, contains('Change_2021')) %>%
  select(!contains('Rep')) %>%
  na.omit()

S_fungi_21_n <- nrow(S_fungi_21)

S_fungi_21 <- S_fungi_21 %>%
  group_by(FungiChange_2021) %>%
  summarise(Responses_2021 = n()) %>%
  mutate(perc = Responses_2021/S_fungi_21_n) %>%
  ungroup()

S_fungi_21_n <- nrow(S_fungi_21)

S_fungi <- cbind(S_fungi_20, S_fungi_21)

```

### Scouting ability

```{r scouting}

S_scout <- S %>%
  select(Location, FindTSLiklihood) %>%
  na.omit()

S_scout_n <- nrow(S_scout)

S_scout <- S_scout %>%
  group_by(FindTSLiklihood) %>%
  summarise(Responses = n()) %>%
  mutate(Percent = round(Responses/S_scout_n, 2)*100) %>%
  ungroup()

```

```{r scouting by role category}

S_scout <- S %>%
  select(starts_with('Role'), FindTSLiklihood) %>%
  pivot_longer(cols = starts_with('Role'), names_to = 'Role', values_to = 'Role_logic') %>%
  na.omit()

S_scout <- S_scout %>%
  select(!Role_logic) %>%
  group_by(Role) %>%
  mutate(Total = n()) %>%
  ungroup() %>%
  group_by(Role, FindTSLiklihood) %>%
  mutate(Responses = n()) %>%
  ungroup() %>%
  mutate(Percent = round(Responses/Total, 2)*100) %>%
  unique()

```

```{r clean up5}

rm(S_scout, S_scout_n, S_fungi, S_fungi_20, S_fungi_21, S_fungi_20_n, S_fungi_21_n)

```

## USDA NASS DATA

```{r USDA data set up}

USDA_21 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2021.csv')
USDA_18 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2018.csv')
USDA_16 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2016.csv')
USDA_14 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2014.csv')
#USDA_10 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2010.csv')

# not including 2010 data because data collection is only for multistate!

USDA <- rbind (USDA_21, USDA_18, USDA_16, USDA_14)
rm(USDA_21, USDA_18, USDA_16, USDA_14)

```

```{r USDA data cleaning}

USDA <- USDA %>%
  relocate(Year, .before = 'Domain') %>% # Move 'Year' column to before 'Domain'
  subset(Geo.Level != 'REGION : MULTI-STATE') %>% # 'Remove any rows containing 'REGION: MULTI-STATE'
  relocate(State, .after = 'Year') %>% # Relocate 'State' to after 'Year'
  select(15:28) %>% # Only retain columns 15-28
  mutate(Name = str_extract(Domain.Category, "(?<=\\().*?(?=\\s*=)")) %>% # Extract the chemical names from the 'Domain.Category' and create a new column named 'Name'
  relocate(Name, .after = Domain.Category) %>% # Relocate Name columns after 'Domain.Category'
  subset(str_detect(Domain.Category, pattern = 'FUNGI')) %>% # Only retain rows where Domain.Category contains 'FUNGI'
  select(!c('Domain', 'Domain.Category')) %>% # Keep all columns besides Domain and Domain.Category
  subset(!is.na(Name)) %>% # Remove rows where Name is NA
  select(!contains('CV')) # Remove columns with CV in name

# Change column names
colnames(USDA) <- c('Year', 'State', 'Name', 
                     'Total_Fungicide_Apps_lb', 
                     'Average_Fungicide_Apps_lb.a', 
                     'Average_Fungicide_Apps_lb.a.y',
                     'Average_Number_Fungicide_Apps', 
                     'Average_Prop_Area_Treated_.')

# Remove weird columns
USDA <- USDA %>%
  subset(!Total_Fungicide_Apps_lb %in% c(' (NA)', ' (D)', ' (Z)' , '')) %>%
  subset(!Average_Fungicide_Apps_lb.a %in% c(' (D)',' (NA)', ' (Z)', '')) %>%
  subset(!Average_Fungicide_Apps_lb.a.y %in% c(' (D)',' (NA)', ' (Z)', '')) %>%
  subset(!Average_Number_Fungicide_Apps %in% c(' (D)',' (NA)', ' (Z)', '')) %>%
  subset(!Average_Prop_Area_Treated_. %in% c(' (D)',' (NA)', ' (Z)', ''))

USDA <- USDA %>%
  mutate(FRAC = ifelse(Name %in% c('AZOXYSTROBIN', 'PYRACLOSTROBIN', 'TRIFLOXYSTROBIN'), '11',
                       ifelse(Name == 'BENZOVINDIFLUPYR', '7', '3'))) %>%
  relocate(FRAC, .after = Name)

USDA <- USDA
USDA$Total_Fungicide_Apps_lb <- as.numeric(gsub(",", "", USDA$Total_Fungicide_Apps_lb))
USDA[5:9] <- sapply(USDA[5:9], as.numeric)
```

```{r set response variables}

response = names(USDA[c(5:9)])
response = set_names(response)

```

### State x FRAC

```{r State by FRAC}
P <- USDA %>%
  #subset(State %in% c('ILLINOIS', 'INDIANA', 'IOWA')) %>%
  group_by(Year, FRAC, State) %>%
  summarise(Total_Fungicide_Apps_lb = sum(Total_Fungicide_Apps_lb),
            Average_Fungicide_Apps_lb.a = mean(Average_Fungicide_Apps_lb.a),
            Average_Fungicide_Apps_lb.a.y = mean(Average_Fungicide_Apps_lb.a.y),
            Average_Number_Fungicide_Apps = mean(Average_Number_Fungicide_Apps),
            Average_Prop_Area_Treated_. = sum(Average_Prop_Area_Treated_.))

scatter_fun = function(x, y) {
  ggplot(P, aes(x = .data[[x]], y = .data[[y]])) +
    geom_col(aes(fill = FRAC), color = 'black') + 
    scale_x_continuous(breaks = seq(1991, 2023, 2)) + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    facet_grid(~State)}

explore.plots = map(response, ~scatter_fun('Year', .x))
explore.plots
```

### State X Fungicide

```{r State by Fungicide}
P1 <- USDA %>%
  subset(State %in% c('ILLINOIS', 'INDIANA', 'IOWA')) %>%
  #subset(State %in% c('ILLINOIS', 'INDIANA', 'IOWA', 'MICHIGAN', 'OHIO')) %>%
  group_by(Year, Name, State) %>%
  summarise(Total_Fungicide_Apps_lb = sum(Total_Fungicide_Apps_lb),
            Average_Fungicide_Apps_lb.a = mean(Average_Fungicide_Apps_lb.a),
            Average_Fungicide_Apps_lb.a.y = mean(Average_Fungicide_Apps_lb.a.y),
            Average_Number_Fungicide_Apps = mean(Average_Number_Fungicide_Apps),
            Average_Prop_Area_Treated_. = sum(Average_Prop_Area_Treated_.))

scatter_fun = function(x, y) {
  ggplot(P1, aes(x = .data[[x]], y = .data[[y]])) +
    geom_col(aes(fill = Name), color = 'black') + 
    scale_x_continuous(breaks = seq(1991, 2023, 2)) + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    facet_grid(~State)}

explore.plots = map(response, ~scatter_fun('Year', .x))
explore.plots
```

