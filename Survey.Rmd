---
title: "Survey"
output: html_document
date: "2025-03-04"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(tidyr)
library(readxl)
library(openxlsx)
library(stringr)
library(ggplot2)
library(ggpubr)
library(sf)
library(tigris)
library(corrplot)
library(purrr)
```

```{r weather data set up, include=FALSE}
# read in weather data

W2020 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Weather data/monthly/TSecon_monthly_weather.xlsx', sheet = '2020')

W2021 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Weather data/monthly/TSecon_monthly_weather.xlsx', sheet = '2021')

# bind all weather data to one frame
W <- rbind(W2020, W2021)

# remove 2020 and 2021 individual dataframes
rm(W2020, W2021)


# tidy weather data

# get month and year, convert to month names
W <- W %>%
  separate(Date, c('Year', 'Month'), '-0')

W$Month <- str_replace_all(W$Month, c("6" = "June", "7" = "July", "8" = "Aug", "9" = "Sept"))

# pivot wider so that each month and weather var is a separate column
W <- W %>%
  pivot_wider(names_from = c('Month', 'Year'), values_from = c(ppt, tmin, tmean, tmax))
```

```{r survey data set up, include=FALSE}
# read in survey response data

S1 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response data/Tar Spot Survey COMPILED.xlsx', sheet = 'Single county') %>%
  unite(County, State, col = "Location", sep = ", ", remove = FALSE) %>%
  drop_na(County)

S2 <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response data/Tar Spot Survey COMPILED.xlsx', sheet = 'Multi-county') %>%
  unite(County, State, col = "Location", sep = ", ", remove = FALSE) %>%
  drop_na(County)

S <- rbind(S1,S2)

rm(S1, S2)
```

```{r survey data check, eval=FALSE}

# Does including the data that is derived from correcting percentages and NASS county statistics change the distribution of the data?

test <- S %>%
  mutate(LOSS_2020 = ifelse(is.na(Operations_2020Loss_perc) & is.na(NASS_County_Yield_2020), Operations_2020Loss, Operations_2020Loss_perc*NASS_County_Yield_2020)) %>%
  relocate(LOSS_2020, .after = Operations_2020Loss_perc) %>%
  mutate(LOSS_2021 = ifelse(is.na(Operations_2021Loss_perc) & is.na(NASS_County_Yield_2021), Operations_2021Loss, Operations_2021Loss_perc*NASS_County_Yield_2021)) %>%
  relocate(LOSS_2021, .after = Operations_2021Loss_perc)

hist(test$LOSS_2020)
hist(test$Operations_2020Loss)
hist(test$LOSS_2021)
hist(test$Operations_2021Loss)

# No, so continue with this data included. 

```

```{r survey data cleaning}

S <- S %>%
  # create final loss columns for each year
  mutate(LOSS_2020 = ifelse(is.na(Operations_2020Loss_perc) & is.na(NASS_County_Yield_2020), Operations_2020Loss, Operations_2020Loss_perc*NASS_County_Yield_2020)) %>%
  relocate(LOSS_2020, .after = Operations_2020Loss_perc) %>%
  mutate(LOSS_2021 = ifelse(is.na(Operations_2021Loss_perc) & is.na(NASS_County_Yield_2021), Operations_2021Loss, Operations_2021Loss_perc*NASS_County_Yield_2021)) %>%
  relocate(LOSS_2021, .after = Operations_2021Loss_perc) %>%
  # remove other columns used to create the final LOSS_2020 and LOSS_2021 columns
  select(!c(starts_with('NASS'), contains('Operations_20'), starts_with('Complete')))
  
```

# HEATMAPS

```{r heatmap prep, include=FALSE}
# prep for heatmaps

# retrieve county-level shapefiles for all states
mi_counties <- counties(state = "MI", cb = TRUE) %>%
  st_transform(crs = 4326)
in_counties <- counties(state = "IN", cb = TRUE) %>%
  st_transform(crs = 4326)
oh_counties <- counties(state = "OH", cb = TRUE) %>%
  st_transform(crs = 4326)
ia_counties <- counties(state = "IA", cb = TRUE) %>%
  st_transform(crs = 4326)
wi_counties <- counties(state = "WI", cb = TRUE) %>%
  st_transform(crs = 4326)
il_counties <- counties(state = "IL", cb = TRUE) %>%
  st_transform(crs = 4326)
pa_counties <- counties(state = "PA", cb = TRUE) %>%
  st_transform(crs = 4326)
mo_counties <- counties(state = "MO", cb = TRUE) %>%
  st_transform(crs = 4326)
ny_counties <- counties(state = "NY", cb = TRUE) %>%
  st_transform(crs = 4326)
mn_counties <- counties(state = "MN", cb = TRUE) %>%
  st_transform(crs = 4326)

# Combine the data for all states
combined_counties_raw <- rbind(mi_counties, in_counties, oh_counties, ia_counties, wi_counties, il_counties, pa_counties, mo_counties, ny_counties, mn_counties)

rm(mi_counties, in_counties, oh_counties, ia_counties, wi_counties, il_counties, pa_counties, mo_counties, ny_counties, mn_counties)
```

```{r response count heatmap}
# heat map of responses

# summarize survey data to count responses by county
S_count <- S %>% group_by(County, State) %>% summarise(Responses = n())

# combine geo info with survey data
combined_counties <- left_join(combined_counties_raw, S_count, by = c('NAME'='County', 'STUSPS'='State'))

# Plot the map
ggplot(data = combined_counties) +
  geom_sf(aes(fill = Responses), color = "black") +
  theme_minimal() +
  labs(title = "County-Level Count of Survey Responses") +
  scale_fill_viridis_c(option = "plasma") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5))

rm(S_count, combined_counties)
```

```{r 2020 loss heatmap}
# heat map of losses 2020

S_loss_2020 <- S %>% group_by(County, State) %>% summarise(Loss = ifelse(all(LOSS_2020 == 0), 0, mean(LOSS_2020, na.rm = TRUE)))

# Combine geo info with survey data
combined_counties <- left_join(combined_counties_raw, S_loss_2020, by = c('NAME'='County', 'STUSPS'='State'))

# Plot the map
ggplot(data = combined_counties) +
  geom_sf(aes(fill = Loss), color = "black") +
  theme_minimal() +
  scale_fill_viridis_c(option = "plasma", limits=c(0, 60)) +
  labs(title = "County-Level Reported Losses Due to Tar Spot in 2020") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5))

rm(combined_counties)
```

```{r 2021 loss heatmap}
# heat map of losses 2020

S_loss_2021 <- S %>% group_by(County, State) %>% summarise(Loss = ifelse(all(LOSS_2021 == 0), 0, 
                                                                    mean(LOSS_2021, na.rm = TRUE)))

# Combine geo info with survey data
combined_counties <- left_join(combined_counties_raw, S_loss_2021, by = c('NAME'='County', 'STUSPS'='State'))

# Plot the map
ggplot(data = combined_counties) +
  geom_sf(aes(fill = Loss), color = "black") +
  theme_minimal() +
  scale_fill_viridis_c(option = "plasma", limits=c(0,60)) +
  labs(title = "County-Level Reported Losses Due to Tar Spot in 2021") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5))

rm(combined_counties)
```

```{r clean up, include=FALSE}

rm(combined_counties_raw)
rm(combined_counties)

```

# LOSS HISTOGRAMS

```{r loss histogram}

S_loss_2020 <- S_loss_2020 %>%
  mutate(Year = '2020')
S_loss_2021 <- S_loss_2021 %>%
  mutate(Year = '2021')
S_loss <- rbind(S_loss_2020, S_loss_2021)

ggplot(S_loss, aes(x=Loss)) + 
  geom_histogram(binwidth=1) +
  facet_grid(~Year)

```

```{r clean up2}

rm(S_loss_2020, S_loss_2021, S_loss)

```

# WEATHER CORRELATIONS

```{r survey + weather data set prep, include=FALSE}

# combine weather and response data

DF <- inner_join(S, W, by = c('Location'))

DF_2020 <- select(DF, c('Location', contains('2020'))) %>%
  select(!c('FungiChange_2020', 'FungiChange_2020_Reported')) %>%
  rename('Loss' = 'LOSS_2020') %>%
  rename_with(~str_remove(., '_2020')) %>% 
  group_by(Location) %>% 
  mutate(Loss = ifelse(all(Loss == 0), 0,
                          mean(Loss, na.rm = TRUE))) %>%
  ungroup() %>%
  select(!'Location')
  
DF_2021 <- select(DF, c('Location', contains('2021'))) %>%
  select(!c('FungiChange_2021', 'FungiChange_2021_Reported')) %>%
  rename('Loss' = 'LOSS_2021') %>%
  rename_with(~str_remove(., '_2021')) %>% 
  group_by(Location) %>% 
  mutate(Loss = ifelse(all(Loss == 0), 0,
                          mean(Loss, na.rm = TRUE))) %>%
  ungroup() %>%
  select(!'Location')

DF <- rbind(DF_2020, DF_2021) %>%
  na.omit()

```

```{r correlation analysis}

# function to calculate correlation test and return p-values
cor_test_results <- function(y, x) {
  cor_test <- cor.test(x, y, use = "complete.obs", method = 'pearson')
  return(c(cor = cor_test$estimate, p_value = cor_test$p.value))
}

# Apply the function to each x variable
results_df <- t(sapply(DF[ , -1], function(x) cor_test_results(DF$Loss, x)))

# Convert the results into a dataframe
results_df <- as.data.frame(results_df)
colnames(results_df) <- c("Correlation", "p")
results_df$code <- 0
results_df <- results_df %>%
  mutate(code = if_else(p < 0.001, "***",
                        if_else(p > 0.001 & p < 0.01, "**",
                                if_else(p >  0.01 & p < 0.05, "*",""))))
results_df$Var <- rownames(results_df)

results_df %>% 
  ggplot(aes(x=reorder(Var, -Correlation, decreasing = TRUE), y = Correlation)) +
  geom_bar(stat = "identity") +
  labs(x="Variable", y = "Correlation strength (Pearson)", title = '') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  geom_text(aes(label = code, vjust = ifelse(Correlation >= 0, -0.25, 1.65))) +
  ylim(-0.7, 0.7)

```

```{r clean up3}

rm(results_df)

```

## ENVIRONMENTAL SCATTERPLOTS

```{r 2020 scatterplots}

# Define data for MA
response = names(DF_2020[c(2:17)])
quant <- 'Loss' 
response = set_names(response)

# Function to output scatter plots for each var

scatter_fun = function(x, y) {
   ggplot(DF_2020, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    theme_bw()
  }

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots

```

```{r 2021 scatterplots}

# Define data for MA

response = names(DF_2021[c(2:17)])
quant <- 'Loss' 
response = set_names(response)

# Function to output scatter plots for each var

scatter_fun = function(x, y) {
   ggplot(DF_2021, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    theme_bw()
  }

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots

```

```{r combined years scatterplots}

# Define data for MA

response = names(DF[c(2:17)])
quant <- 'Loss' 
response = set_names(response)

# Function to output scatter plots for each var

scatter_fun = function(x, y) {
   ggplot(DF, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    theme_bw()
  }

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots

```

```{r density, loess and lm fits}

DF <- DF %>% select(!contains('Sept')) %>% filter(Loss > 0)

response = names(DF[c(2:13)]) 
quant <- 'Loss' 
response = set_names(response)

# Function to output scatter plots for each var

scatter_fun = function(x, y) {
   ggplot(DF, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    stat_density(aes(x=.data[[x]], y=(18*(..scaled..))), position="identity", geom="line", color = 'red', linewidth = 1.5) +
    geom_smooth(method='loess', color = 'blue', se = FALSE) +
    geom_smooth(method='lm', color = 'darkgrey', se = FALSE) +
    stat_regline_equation()+
    stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")), label.x.npc = "centre") + 
    theme_bw() +
    ylim(0, 60)
  }


# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots

```

```{r histogram and density plots}

response = names(DF[c(2:13)]) 
quant <- 'Loss' 
response = set_names(response)

# Function to output scatter plots for each var

scatter_fun = function(x, y) {
   ggplot(DF, aes(x = .data[[x]])) +
    geom_histogram(aes(y = ..density..), fill = 'gray', color = 'black', binwidth = 0.25) +
    geom_density(color = 'red', linewidth = 1.5)+
    #geom_smooth(method='loess', color = 'blue', se = FALSE) +
    #geom_smooth(method='lm', color = 'blue', se = FALSE) +
    #stat_regline_equation()+
    #stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),
           #label.x.npc = "centre") + 
    theme_bw() 
  }


# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots
```

```{r individual Gaussian curves- ppt}

G_ppt <- DF %>%
  filter(Loss > 0) %>%
  select(Loss, contains('ppt'))

response = names(G_ppt[c(2:4)]) 
quant <- 'Loss' 

scatter_fun = function(x, y) {
  
  # Fit the nonlinear model using nls
  model <- nls(Loss ~ k*exp(-1/2*(G_ppt[[x]]-mu)^2/sigma^2), 
               data = G_ppt, 
               start = c(mu = 100, sigma = 20, k = 10))
  
  # Extract coefficients
  coefficients <- coef(model)
  
  # Plot 
  ggplot(data = G_ppt, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    geom_smooth(method = 'nls',
                color = 'blue',
                formula = y ~ k * exp(-1/2 * (x - mu)^2 / sigma^2),
                method.args = list(start = c(mu = 100, sigma = 20, k = 10)),
                se = FALSE) +
    theme_bw() +
    theme(panel.border = element_blank()) +
    annotate("text", 
             x = Inf, y = Inf, vjust = 2, hjust = 1,
             #x = 0.9, y = 0.9, hjust = 1, vjust = 1, halign = 0.5, valign = 0.5,
             label = paste("Amplitude =", round(coefficients[3], 2),
                           ", Standard deviation =", round(coefficients[2], 2),
                           ", Mean =", round(coefficients[1], 2)))
}

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots

```

```{r individual Gaussian curves - tmax}

G_tmax <- DF %>%
  filter(Loss > 0) %>%
  select(Loss, contains('tmax'))

response = names(G_tmax[c(2:4)]) 
quant <- 'Loss' 

scatter_fun = function(x, y) {
  
  # Fit the nonlinear model using nls
  model <- nls(Loss ~ k*exp(-1/2*(G_tmax[[x]]-mu)^2/sigma^2), 
               data = G_tmax, 
               start = c(mu = 27, sigma = 5, k = 10))
  
  # Extract coefficients
  coefficients <- coef(model)
  
  # Plot 
  ggplot(data = G_tmax, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    geom_smooth(method = 'nls',
                color = 'blue',
                formula = y ~ k * exp(-1/2 * (x - mu)^2 / sigma^2),
                method.args = list(start = c(mu = 27, sigma = 5, k = 10)),
                se = FALSE) +
    theme_bw() +
    theme(panel.border = element_blank()) +
    annotate("text", 
             x = Inf, y = Inf, vjust = 2, hjust = 1,
             #x = 0.9, y = 0.9, hjust = 1, vjust = 1, halign = 0.5, valign = 0.5,
             label = paste("Amplitude =", round(coefficients[3], 2),
                           ", Standard deviation =", round(coefficients[2], 2),
                           ", Mean =", round(coefficients[1], 2)))
}

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots
```

```{r individual Gaussian curves - tmin, eval = FALSE}

G_tmin <- DF %>%
  filter(Loss > 0) %>%
  select(Loss, contains('tmin'))

response = names(G_tmin[c(2:4)]) 
quant <- 'Loss' 

scatter_fun = function(x, y) {
  
  # Fit the nonlinear model using nls
  model <- nls(Loss ~ k*exp(-1/2*(G_tmin[[x]]-mu)^2/sigma^2), 
               data = G_tmin, 
               start = c(mu = 16, sigma = 5, k = 10))
  
  # Extract coefficients
  coefficients <- coef(model)
  
  # Plot 
  ggplot(data = G_tmin, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    geom_smooth(method = 'nls',
                color = 'blue',
                formula = y ~ k * exp(-1/2 * (x - mu)^2 / sigma^2),
                method.args = list(start = c(mu = 16, sigma = 5, k = 10)),
                se = FALSE) +
    theme_bw() +
    theme(panel.border = element_blank()) +
    annotate("text", 
             x = Inf, y = Inf, vjust = 2, hjust = 1,
             #x = 0.9, y = 0.9, hjust = 1, vjust = 1, halign = 0.5, valign = 0.5,
             label = paste("Amplitude =", round(coefficients[3], 2),
                           ", Standard deviation =", round(coefficients[2], 2),
                           ", Mean =", round(coefficients[1], 2)))
}

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots
```

```{r individual Gaussian curves - tmean, eval = FALSE}

G_tmean <- DF %>%
  filter(Loss > 0) %>%
  select(Loss, contains('tmean'))

response = names(test[c(2:4)]) 
quant <- 'Loss' 

scatter_fun = function(x, y) {
  
  # Fit the nonlinear model using nls
  model <- nls(Loss ~ k*exp(-1/2*(G_tmean[[x]]-mu)^2/sigma^2), 
               data = G_tmean, 
               start = c(mu = 18, sigma = 5, k = 10))
  
  # Extract coefficients
  coefficients <- coef(model)
  
  # Plot 
  ggplot(data = test, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point() +
    geom_smooth(method = 'nls',
                color = 'blue',
                formula = y ~ k * exp(-1/2 * (x - mu)^2 / sigma^2),
                method.args = list(start = c(mu = 16, sigma = 5, k = 10)),
                se = FALSE) +
    theme_bw() +
    theme(panel.border = element_blank()) +
    annotate("text", 
             x = Inf, y = Inf, vjust = 2, hjust = 1,
             label = paste("Amplitude =", round(coefficients[3], 2),
                           ", Standard deviation =", round(coefficients[2], 2),
                           ", Mean =", round(coefficients[1], 2)))
}

# Output plots 
explore.plots = map(response, ~scatter_fun(.x, quant))
explore.plots
```

```{r cumulative precipitation density plot}

CUSUM_ppt <- DF %>% 
  filter(Loss > 0) %>%
  rowwise() %>%
  mutate(ppt_CUSUM = sum(across(c(ppt_July, ppt_Aug))))

ggplot(data = CUSUM_ppt, aes(x=ppt_CUSUM, y=Loss)) +
  geom_point() +
  stat_density(aes(x=ppt_CUSUM, y=2500*(..density..)), position="identity", geom="line", color = 'red', linewidth = 1.5)

```

```{r clean up4}

rm(DF_2020, DF_2021, explore.plots, results_df, G_ppt, G_tmax, G_tmean, G_tmin, CUSUM_ppt) 

```


## SUMMARIZING CATEGORICAL RESPONSES

### Historical fungicide use

```{r historical fungicide use}

HF <- S %>% select(contains('Hist')) %>% select(!ends_with('Reported')) %>% select(!contains('Other'))

# Removing '_Reported' columns - all data has been cleaned. 
# Also removing observations with entries in "other" actually belonged in existing categories, or were nonsense, so removing

column_sums <- colSums(!is.na(HF))
print(column_sums)

```

```{r historical fungicide program matrix}

# change all Yes to 1

CO <- as.data.frame(ifelse(!is.na(HF) & HF == "Yes", 1, 0))

# Remove rows with no coinfections by counting across data columns and filtering
CO <- CO %>%
  rowwise() %>%
  mutate(coinfection_check = sum(c_across(c("HistFungiStrat_V10",
                                            "HistFungiStrat_V10_14",
                                            "HistFungiStrat_VTR1",
                                            "HistFungiStrat_R2",
                                            "HistFungiStrat_PostR2",
                                            "HistFungiStrat_None" ))))

CO_matrix <- CO %>% 
  count(HistFungiStrat_V10,
        HistFungiStrat_V10_14,
        HistFungiStrat_VTR1, 
        HistFungiStrat_R2, 
        HistFungiStrat_PostR2, 
        HistFungiStrat_None)

# DO NOT OVERWRITE
#write.xlsx(CO_matrix, '/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response data/CO_matrixMultiCounty.xlsx', overwrite=FALSE)

rm(CO, CO_matrix, HF)

```

```{r historical fungicide program visualization}
# Load in fixed matrix

coinfection_data <- read_excel('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/Response Data/CO_matrix FIXED.xlsx')
colnames(coinfection_data)[1] <- 'X1'

# Melt data so that each combination is represented by its own Row
library(reshape2)
ReshapedData <- melt(coinfection_data, value.name = 'Responses')

# Reorder
mylevels <- c('V10', 'V10-V14', 'VT/R1', 'R2', 'PostR2', 'None')

# reorder factors
ReshapedData$X1 <- factor(ReshapedData$X1,levels=mylevels)
ReshapedData$variable <- factor(ReshapedData$variable, levels=mylevels)
 
# Heatmap 
ggplot(ReshapedData, aes(X1, variable, fill= Responses)) + 
  geom_tile(color = 'white')

rm (ReshapedData, coinfection_data)
```

### Increase in fungicide use

```{r fungicide use - farmers only}

S_fungi_20 <- S %>%
  select(Role_Farmer, Location, contains('Change_2020')) %>%
  select(!contains('Rep')) %>%
  na.omit()

S_fungi_20_n <- nrow(S_fungi_20)

S_fungi_20 <- S_fungi_20 %>%
  group_by(FungiChange_2020) %>%
  summarise(Responses_2020 = n()) %>%
  mutate(perc = Responses_2020/S_fungi_20_n) %>%
  ungroup()

S_fungi_21 <- S %>%
  select(Role_Farmer, Location, contains('Change_2021')) %>%
  select(!contains('Rep')) %>%
  na.omit()

S_fungi_21_n <- nrow(S_fungi_21)

S_fungi_21 <- S_fungi_21 %>%
  group_by(FungiChange_2021) %>%
  summarise(Responses_2021 = n()) %>%
  mutate(perc = Responses_2021/S_fungi_21_n) %>%
  ungroup()

S_fungi_21_n <- nrow(S_fungi_21)

S_fungi <- cbind(S_fungi_20, S_fungi_21)

```

### Scouting ability

```{r scouting}

S_scout <- S %>%
  select(Location, FindTSLiklihood) %>%
  na.omit()

S_scout_n <- nrow(S_scout)

S_scout <- S_scout %>%
  group_by(FindTSLiklihood) %>%
  summarise(Responses = n()) %>%
  mutate(Percent = round(Responses/S_scout_n, 2)*100) %>%
  ungroup()

```

```{r scouting by role category}

S_scout <- S %>%
  select(starts_with('Role'), FindTSLiklihood) %>%
  pivot_longer(cols = starts_with('Role'), names_to = 'Role', values_to = 'Role_logic') %>%
  na.omit()

S_scout <- S_scout %>%
  select(!Role_logic) %>%
  group_by(Role) %>%
  mutate(Total = n()) %>%
  ungroup() %>%
  group_by(Role, FindTSLiklihood) %>%
  mutate(Responses = n()) %>%
  ungroup() %>%
  mutate(Percent = round(Responses/Total, 2)*100) %>%
  unique()

```

```{r clean up5}

rm(S_scout, S_scout_n, S_fungi, S_fungi_20, S_fungi_21, S_fungi_20_n, S_fungi_21_n)

```

## USDA NASS DATA

```{r USDA data set up}

USDA_21 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2021.csv')
USDA_18 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2018.csv')
USDA_16 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2016.csv')
USDA_14 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2014.csv')
#USDA_10 <- read.csv('/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Economics survey/USDA NASS/2010.csv')

# not including 2010 data because data collection is only for multistate!

USDA <- rbind (USDA_21, USDA_18, USDA_16, USDA_14)
rm(USDA_21, USDA_18, USDA_16, USDA_14)

```

```{r USDA data cleaning}

USDA <- USDA %>%
  relocate(Year, .before = 'Domain') %>% # Move 'Year' column to before 'Domain'
  subset(Geo.Level != 'REGION : MULTI-STATE') %>% # 'Remove any rows containing 'REGION: MULTI-STATE'
  relocate(State, .after = 'Year') %>% # Relocate 'State' to after 'Year'
  select(15:28) %>% # Only retain columns 15-28
  mutate(Name = str_extract(Domain.Category, "(?<=\\().*?(?=\\s*=)")) %>% # Extract the chemical names from the 'Domain.Category' and create a new column named 'Name'
  relocate(Name, .after = Domain.Category) %>% # Relocate Name columns after 'Domain.Category'
  subset(str_detect(Domain.Category, pattern = 'FUNGI')) %>% # Only retain rows where Domain.Category contains 'FUNGI'
  select(!c('Domain', 'Domain.Category')) %>% # Keep all columns besides Domain and Domain.Category
  subset(!is.na(Name)) %>% # Remove rows where Name is NA
  select(!contains('CV')) # Remove columns with CV in name

# Change column names
colnames(USDA) <- c('Year', 'State', 'Name', 
                     'Total_Fungicide_Apps_lb', 
                     'Average_Fungicide_Apps_lb.a', 
                     'Average_Fungicide_Apps_lb.a.y',
                     'Average_Number_Fungicide_Apps', 
                     'Average_Prop_Area_Treated_.')

# Remove weird columns
USDA <- USDA %>%
  subset(!Total_Fungicide_Apps_lb %in% c(' (NA)', ' (D)', ' (Z)' , '')) %>%
  subset(!Average_Fungicide_Apps_lb.a %in% c(' (D)',' (NA)', ' (Z)', '')) %>%
  subset(!Average_Fungicide_Apps_lb.a.y %in% c(' (D)',' (NA)', ' (Z)', '')) %>%
  subset(!Average_Number_Fungicide_Apps %in% c(' (D)',' (NA)', ' (Z)', '')) %>%
  subset(!Average_Prop_Area_Treated_. %in% c(' (D)',' (NA)', ' (Z)', ''))

USDA <- USDA %>%
  mutate(FRAC = ifelse(Name %in% c('AZOXYSTROBIN', 'PYRACLOSTROBIN', 'TRIFLOXYSTROBIN'), '11',
                       ifelse(Name == 'BENZOVINDIFLUPYR', '7', '3'))) %>%
  relocate(FRAC, .after = Name)

USDA <- USDA
USDA$Total_Fungicide_Apps_lb <- as.numeric(gsub(",", "", USDA$Total_Fungicide_Apps_lb))
USDA[5:9] <- sapply(USDA[5:9], as.numeric)
```

```{r set response variables}

response = names(USDA[c(5:9)])
response = set_names(response)

```

### State x FRAC

```{r State by FRAC}
P <- USDA %>%
  #subset(State %in% c('ILLINOIS', 'INDIANA', 'IOWA')) %>%
  group_by(Year, FRAC, State) %>%
  summarise(Total_Fungicide_Apps_lb = sum(Total_Fungicide_Apps_lb),
            Average_Fungicide_Apps_lb.a = mean(Average_Fungicide_Apps_lb.a),
            Average_Fungicide_Apps_lb.a.y = mean(Average_Fungicide_Apps_lb.a.y),
            Average_Number_Fungicide_Apps = mean(Average_Number_Fungicide_Apps),
            Average_Prop_Area_Treated_. = sum(Average_Prop_Area_Treated_.))

scatter_fun = function(x, y) {
  ggplot(P, aes(x = .data[[x]], y = .data[[y]])) +
    geom_col(aes(fill = FRAC), color = 'black') + 
    scale_x_continuous(breaks = seq(1991, 2023, 2)) + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    facet_grid(~State)}

explore.plots = map(response, ~scatter_fun('Year', .x))
explore.plots
```

### State X Fungicide

```{r State by Fungicide}
P1 <- USDA %>%
  subset(State %in% c('ILLINOIS', 'INDIANA', 'IOWA')) %>%
  #subset(State %in% c('ILLINOIS', 'INDIANA', 'IOWA', 'MICHIGAN', 'OHIO')) %>%
  group_by(Year, Name, State) %>%
  summarise(Total_Fungicide_Apps_lb = sum(Total_Fungicide_Apps_lb),
            Average_Fungicide_Apps_lb.a = mean(Average_Fungicide_Apps_lb.a),
            Average_Fungicide_Apps_lb.a.y = mean(Average_Fungicide_Apps_lb.a.y),
            Average_Number_Fungicide_Apps = mean(Average_Number_Fungicide_Apps),
            Average_Prop_Area_Treated_. = sum(Average_Prop_Area_Treated_.))

scatter_fun = function(x, y) {
  ggplot(P1, aes(x = .data[[x]], y = .data[[y]])) +
    geom_col(aes(fill = Name), color = 'black') + 
    scale_x_continuous(breaks = seq(1991, 2023, 2)) + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    facet_grid(~State)}

explore.plots = map(response, ~scatter_fun('Year', .x))
explore.plots
```

